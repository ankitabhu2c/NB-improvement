# NB-improvement
Nb classier greatly simplifies learning by assuming the features are independent , The assumption made in na√Øve Bayes is; attribute is conditionally independent given the class however the attribute independence assumption made by the NB classier harms its classification performance when it is violated in reality better predictor of NB accuracy is the amount of information lost because of independence assumption. In this paper the author proposed a novel method which penalizes the classes which have higher chances of classification error. The author reports the result on several real-world data set which shows the efficiency of the proposed model. In order to relax the attribute assumption NB classifier while at the same time maintaining its simplicity and efficiency researchers have proposed many effective methods.
